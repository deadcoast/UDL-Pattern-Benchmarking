# file: /Users/deadcoast/github/continuous-thought-machines/tasks/rl/train.py
# hypothesis_version: 6.148.7

[0.0, 1e-08, 1e-05, 0.0005, 0.1, 0.25, 0.5, 0.95, 0.99, 1.0, 100, 128, 500, 1000, 1000000, '+', '--anneal_lr', '--clip_coef', '--clip_vloss', '--d_input', '--d_model', '--deep_memory', '--device', '--discount_gamma', '--do_normalisation', '--dropout', '--ent_coef', '--env_id', '--gae_lambda', '--iterations', '--log_dir', '--lr', '--mask_velocity', '--max_grad_norm', '--memory_hidden_dims', '--memory_length', '--model_type', '--n_synch_out', '--neuron_select_type', '--norm_adv', '--num_envs', '--num_minibatches', '--num_steps', '--reload', '--run_name', '--save_every', '--seed', '--synapse_depth', '--target_kl', '--tb_log_dir', '--total_timesteps', '--track_every', '--update_epochs', '--vf_coef', 'Acrobot-v1', 'CartPole-v1', 'Dropout rate.', 'Entropy coefficient.', 'Environment ID.', 'Learning rate.', 'MiniGrid', 'Random seed.', 'Train CTM with RL.', 'Training', 'Use deep NLMs.', '__main__', '_r', 'action_logits', 'action_probs', 'actions', 'args', 'charts/SPS', 'charts/lr', 'cpu', 'ctm', 'cuda', 'default_run', 'episode', 'final_info', 'first-last', 'global_step', 'grad_norms/total', 'hyperparameters', 'inputs', 'l', 'length', 'logs/rl/acrobot', 'logs/runs', 'losses/approx_kl', 'losses/clipfrac', 'losses/entropy', 'losses/old_approx_kl', 'losses/policy_loss', 'losses/value_loss', 'lr', 'lstm', 'model_state_dict', 'navigation-backbone', 'optimizer_state_dict', 'post_activations', 'pre_activations', 'r', 'random', 'random-pairing', 'return', 'rewards', 'rgb_array', 'step', 'synchronisation', 'train. iter', 'training_iteration', 'values']